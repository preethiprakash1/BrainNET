{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries and Packages","metadata":{}},{"cell_type":"code","source":"!pip install -qqq torchmetrics\n!pip install -qqq pytorch-lightning\n!pip install -qqq segmentation-models-pytorch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport glob\n\nimport gc\nimport time\n\nimport wandb\nfrom pytorch_lightning.loggers import WandbLogger\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchmetrics\n\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\nfrom IPython.display import Image\nfrom skimage import io\n\nimport segmentation_models_pytorch as smp\n\nfrom pprint import pprint\n\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom IPython.display import display\n\nfrom PIL import Image\n\nimport torchvision\nfrom torchvision import transforms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"img_data = pd.read_csv('../input/lgg-mri-segmentation/kaggle_3m/data.csv') \nimg_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = []\nfor sub_dir_path in glob.glob(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n    try:\n        dir_name = sub_dir_path.split('/')[-1]\n        for filename in os.listdir(sub_dir_path):\n            mask_path = sub_dir_path + '/' + filename\n            data_path.extend([dir_name, mask_path])\n    except Exception as e:\n        print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = data_path[::2]\nmasks = data_path[1::2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data={\"patient_id\": filenames,\"img_path\": masks})\nprint(df.shape)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_img = df[~df['img_path'].str.contains(\"mask\")]\nmask_img = df[df['img_path'].str.contains(\"mask\")]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_img, mask_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = sorted(original_img[\"img_path\"].values, key=lambda x : int(x[89:-4]))\nmasks = sorted(mask_img[\"img_path\"].values, key=lambda x : int(x[89:-9]))\n\nidx = random.randint(0, len(imgs)-1)\nprint(\"Image path:\", imgs[idx], \"\\nMask path:\", masks[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_df = pd.DataFrame({\"patient_id\": original_img.patient_id.values,\"img_path\": imgs,\n                           'mask_path':masks})\nmri_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_diagnosis(img_path):\n    image = cv2.imread(img_path)\n    value = np.max(image)\n    if value > 0:\n        return 1\n    else:\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_df['mask'] = mri_df['mask_path'].apply(lambda x: get_diagnosis(x))\n\nmri_df['mask_path'] = mri_df['mask_path'].apply(lambda x: str(x))\n\nprint(mri_df.shape)\nmri_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_df.drop(columns=['patient_id'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"positive_samples = mri_df[mri_df['mask_path'].apply(get_diagnosis) == 1].sample(n=1183, random_state=42)\n\ntumor_count_before = mri_df['mask_path'].apply(get_diagnosis).sum()\nnon_tumor_count_before = len(mri_df) - tumor_count_before\n\ntransformed_data = []\n\nfor idx, row in positive_samples.iterrows():\n    image_path = row['img_path']\n    mask_path = row['mask_path']\n    \n    image = cv2.imread(image_path)\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    \n    new_image_path = f\"{idx}.tif\"\n    new_mask_path = f\"{idx}_mask.tif\"\n    \n    scale_factor = random.uniform(0.9, 1.1)\n    image = cv2.resize(image, None, fx=scale_factor, fy=scale_factor)\n    mask = cv2.resize(mask, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_NEAREST)\n    \n    angle = random.uniform(-180, 180)\n    rows, cols, _ = image.shape\n    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n    image = cv2.warpAffine(image, M, (cols, rows))\n    mask = cv2.warpAffine(mask, M, (cols, rows), flags=cv2.INTER_NEAREST)\n    \n    if random.random() < 0.5:\n        image = cv2.transpose(image)\n        mask = cv2.transpose(mask)\n        \n    cv2.imwrite(new_image_path, image)\n    cv2.imwrite(new_mask_path, mask)\n    \n    transformed_data.append({'img_path': new_image_path, 'mask_path': new_mask_path})\n\nmri_df = pd.concat([mri_df, pd.DataFrame(transformed_data)], ignore_index=True)\n\ntumor_count_after = mri_df['mask_path'].apply(get_diagnosis).sum()\nnon_tumor_count_after = len(mri_df) - tumor_count_after\n\nprint(\"Total images with tumors before transformations:\", tumor_count_before)\nprint(\"Total images without tumors before transformations:\", non_tumor_count_before)\nprint(\"Total images with tumors after transformations:\", tumor_count_after)\nprint(\"Total images without tumors after transformations:\", non_tumor_count_after)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"image_transform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n])\n\nmask_transform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_data(img, mask):\n    img = img / 255.\n    mask = mask / 255.\n    mask[mask > 0.5] = 1.0\n    mask[mask <= 0.5] = 0.0\n    \n    return (img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df= mri_df, \n                 adjust_data = adjust_data, \n                 image_transform=image_transform, mask_transform=mask_transform):\n        self.df = df\n        self.image_transform = image_transform\n        self.mask_transform = mask_transform\n        self.adjust_data= adjust_data\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_path = self.df.loc[idx, 'img_path']\n        mask_path = self.df.loc[idx, 'mask_path']\n\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(mask_path)\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n\n        image, mask = self.adjust_data(image, mask)\n\n        if self.image_transform:\n            image = self.image_transform(image).float()\n\n        if self.mask_transform:\n            mask = self.mask_transform(mask)\n        return image, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df= mri_df,\n                    train_num= int(mri_df.shape[0] * .6), \n                    valid_num= int(mri_df.shape[0] * .8), \n                    bs = 16):\n    \n    train = df[:train_num].reset_index(drop=True)\n    valid = df[train_num : valid_num].reset_index(drop=True)    \n    test  = df[valid_num:].reset_index(drop=True)\n\n    train_ds = MyDataset(df = train)\n    valid_ds = MyDataset(df = valid)\n    test_ds = MyDataset(df = test)\n\n    train_loader = DataLoader(train_ds, batch_size = bs, num_workers = os.cpu_count(), shuffle = True)\n    valid_loader = DataLoader(valid_ds, batch_size = bs, num_workers = os.cpu_count(), shuffle = False)\n    test_loader = DataLoader(test_ds, batch_size = 4, num_workers = os.cpu_count(), shuffle = True)\n    \n    print(\"DataLoader Completed\")\n    \n    return train_loader, valid_loader, test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = prepare_loaders(df= mri_df,\n                                                            train_num= int(mri_df.shape[0] * .65), \n                                                            valid_num= int(mri_df.shape[0] * .85), \n                                                            bs = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = next(iter(train_loader))\ndata[0].shape, data[1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNet Model","metadata":{}},{"cell_type":"code","source":"######################################## Double Convolution\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\n######################################## Maxpooling followed by Double Convolution\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\n######################################## Upsampling followed by Double Convolution\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up_conv = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n        )\n        self.conv = DoubleConv(out_channels * 2, out_channels) #### change here for regular\n\n\n    def forward(self, x1, x2):\n        x1 = self.up_conv(x1)\n        x = torch.cat([x1, x2], dim=1) ### delte here for regular\n        x = self.conv(x)\n        return x\n\n######################################## Output layer (1x1 Convolution followed by Sigmoid activation)\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv_sigmoid = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.conv_sigmoid(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet_Skip(nn.Module):\n    def __init__(self, name, n_channels, n_classes):\n        super(UNet_Skip, self).__init__()\n        self.name = name\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n\n        self.inputL = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        self.down4 = Down(512, 1024)\n        self.up1 = Up(1024, 512)\n        self.up2 = Up(512, 256)\n        self.up3 = Up(256, 128)\n        self.up4 = Up(128, 64)\n        self.outputL = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x0 = self.inputL(x)\n\n        x1 = self.down1(x0)\n        x2 = self.down2(x1)\n        x3 = self.down3(x2)\n        x4 = self.down4(x3)\n\n        x = self.up1(x4, x3)\n        x = self.up2(x, x2)\n        x = self.up3(x, x1)\n        x = self.up4(x, x0)\n\n        x = self.outputL(x)\n\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model= UNet_Skip(\"test\", 3, 1).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(2022)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"def accuracy_function(target, predicted):\n    true_positives = np.sum(predicted * target)\n    true_negatives = np.sum((1 - predicted) * (1 - target))\n    total_pixels = len(predicted)\n    acc = (true_positives + true_negatives) / total_pixels\n    return acc.item()\n\ndef precision_function(target, predicted):\n    true_positives = np.sum(predicted * target)\n    false_positives = np.sum(predicted * (1 - target))\n    precision = true_positives / (true_positives + false_positives + 1e-7)  # Add a small epsilon value to avoid division by zero\n    return precision.item()\n\ndef recall_function(target, predicted):\n    true_positives = np.sum(predicted * target)\n    false_negatives = np.sum((1 - predicted) * target)\n    recall = true_positives / (true_positives + false_negatives + 1e-7)  # Add a small epsilon value to avoid division by zero\n    return recall.item()\n\ndef dice_coeff_binary(y_true, y_pred):\n    \"\"\"Compute Dice coefficient for binary segmentation.\"\"\"\n    eps = 1e-9\n    inter = np.dot(y_pred, y_true)\n    union = np.sum(y_pred) + np.sum(y_true)\n    return ((2 * inter + eps) / (union + eps)).item()\n\ndef specificity_function(y_true, y_pred):\n    \"\"\"Compute specificity for binary classification.\"\"\"\n    true_negatives = np.sum((1 - y_pred) * (1 - y_true))\n    actual_negatives = np.sum(1 - y_true)\n    return true_negatives / actual_negatives\n\ndef intersection_over_union(y_true, y_pred):\n    \"\"\"Compute Intersection over Union for binary segmentation.\"\"\"\n    eps = 1e-9\n    intersection = np.sum(y_pred * y_true)\n    union = np.sum(y_pred) + np.sum(y_true) - intersection\n    iou = (intersection + eps) / (union + eps)\n    return iou.item()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"model = UNet_Skip('test', n_channels=3, n_classes=1)\nmodel.cuda()\n\n# Initialize loss and optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\n# Weighted binary cross-entropy loss\n# pos_weight = torch.tensor([5.0]).cuda()  # Adjust this weight accordingly\n# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\ncriterion = torch.nn.BCEWithLogitsLoss()\n\n# Training\nnum_epochs = 20\ntrain_losses = []\nval_losses = []\ntrain_dices = []\nval_dices = []\n\nbest_val_loss = float('inf') \nfor epoch in range(num_epochs):\n    model.train()\n    total_accuracy = 0.0\n    total_precision = 0.0\n    total_recall = 0.0\n    total_dice = 0.0\n    total_specificity = 0.0\n    total_iou = 0.0\n\n    for i, (images, masks) in enumerate(train_loader):\n        images = images.cuda()\n        masks = masks.cuda()\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        threshold = 0.5\n        outputs_thresholded = (outputs > threshold).float()\n\n        outputs_flat = outputs.view(-1)\n        masks_flat = masks.view(-1)\n\n        loss = criterion(outputs_flat, masks_flat)\n        print(f\"Epoch {epoch+1}/{num_epochs}, Batch {i+1}, Loss: {loss}\")\n\n        loss.backward()\n        optimizer.step()\n\n        image_index = 0  \n        single_mask = masks[image_index].cpu().detach().numpy()\n        single_output = outputs_thresholded[image_index].cpu().detach().numpy()\n\n        outputs_thresholded = outputs_thresholded.cpu().detach().numpy().reshape(-1)\n        masks = masks.cpu().detach().numpy().reshape(-1)\n\n        accuracy = accuracy_function(masks, outputs_thresholded)\n        precision = precision_function(masks, outputs_thresholded)\n        recall = recall_function(masks, outputs_thresholded)\n        dice_score = dice_coeff_binary(masks, outputs_thresholded)\n        specificity = specificity_function(masks, outputs_thresholded)\n        iou = intersection_over_union(masks, outputs_thresholded)\n\n        total_accuracy += accuracy\n        total_precision += precision\n        total_recall += recall\n        total_dice += dice_score\n        total_specificity += specificity\n        total_iou += iou\n\n        print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, Dice Score: {dice_score}, Specificity: {specificity}, IOU: {iou}\")\n\n    avg_accuracy = total_accuracy / len(train_loader)\n    avg_precision = total_precision / len(train_loader)\n    avg_recall = total_recall / len(train_loader)\n    avg_dice = total_dice / len(train_loader)\n    avg_specificity = total_specificity / len(train_loader)\n    avg_iou = total_iou / len(train_loader)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss}, Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average Dice: {avg_dice}, Average Specificity: {avg_specificity}, Average IOU: {avg_iou}\")\n\n    train_losses.append(loss)\n    train_dices.append(avg_dice)\n    \n    model.eval()\n    total_val_accuracy = 0.0\n    total_val_precision = 0.0\n    total_val_recall = 0.0\n    total_val_dice = 0.0\n    total_val_specificity = 0.0\n    total_val_loss = 0.0\n    total_val_iou = 0.0\n\n    with torch.no_grad():\n        for i, (images, masks) in enumerate(valid_loader):\n            images = images.cuda()\n            masks = masks.cuda()\n\n            outputs = model(images)\n            threshold = 0.5\n            outputs_thresholded = (outputs > threshold).float()\n\n            outputs_flat = outputs.view(-1)\n            masks_flat = masks.view(-1)\n\n            loss = criterion(outputs_flat, masks_flat)\n            total_val_loss += loss.item()\n\n            outputs_thresholded = outputs_thresholded.cpu().detach().numpy().reshape(-1)\n            masks = masks.cpu().detach().numpy().reshape(-1)\n\n            accuracy = accuracy_function(masks, outputs_thresholded)\n            precision = precision_function(masks, outputs_thresholded)\n            recall = recall_function(masks, outputs_thresholded)\n            dice_score = dice_coeff_binary(masks, outputs_thresholded)\n            specificity = specificity_function(masks, outputs_thresholded)\n            iou = intersection_over_union(masks, outputs_thresholded)\n\n            total_val_accuracy += accuracy\n            total_val_precision += precision\n            total_val_recall += recall\n            total_val_dice += dice_score\n            total_val_specificity += specificity\n            total_val_iou += iou\n\n            print(f\"Epoch {epoch+1}/{num_epochs}, Validation Batch {i+1}/{len(valid_loader)}, Loss: {loss.item()}\")\n\n        avg_val_accuracy = total_val_accuracy / len(valid_loader)\n        avg_val_precision = total_val_precision / len(valid_loader)\n        avg_val_recall = total_val_recall / len(valid_loader)\n        avg_val_dice = total_val_dice / len(valid_loader)\n        avg_val_specificity = total_val_specificity / len(valid_loader)\n        avg_val_loss = total_val_loss / len(valid_loader)\n        avg_val_iou = total_val_iou / len(valid_loader)\n        \n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), '/kaggle/working/model_best.ckpt')\n            print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss improved. Model saved.\")\n\n        val_losses.append(avg_val_loss)\n        val_dices.append(avg_val_dice)\n\n        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss}, Average Accuracy: {avg_val_accuracy}, Average Precision: {avg_val_precision}, Average Recall: {avg_val_recall}, Average Dice: {avg_val_dice}, Average Specificity: {avg_val_specificity}, Average IOU: {avg_val_iou}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nepochs = range(1, num_epochs + 1)\n\ntrain_losses_np = np.array([loss.cpu().detach().numpy() for loss in train_losses])\nval_losses_np = np.array([loss for loss in val_losses])\n\nplt.figure(figsize=(10, 5))\nplt.plot(epochs, train_losses_np, label='Training Loss')\nplt.plot(epochs, val_losses_np, label='Validation Loss')\nplt.title('Training and Validation Loss Curves')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(epochs)\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, num_epochs + 1)\n\n\n\nplt.figure(figsize=(10, 5))\nplt.plot(epochs, train_dices, label='Training DICE')\nplt.plot(epochs, val_dices, label='Validation DICE')\nplt.title('Training and Validation DICE Scores')\nplt.xlabel('Epochs')\nplt.ylabel('DICE Score')\nplt.xticks(epochs)\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Testing","metadata":{}},{"cell_type":"code","source":"\n    model.eval()\n    total_test_accuracy = 0.0\n    total_test_precision = 0.0\n    total_test_recall = 0.0\n    total_test_dice = 0.0\n    total_test_specificity = 0.0\n    total_test_loss = 0.0\n    total_test_iou = 0.0\n\n    with torch.no_grad():\n        for i, (images, masks) in enumerate(test_loader):\n            images = images.cuda()\n            masks = masks.cuda()\n\n            outputs = model(images)\n            threshold = 0.5\n            outputs_thresholded = (outputs > threshold).float()\n\n            outputs_flat = outputs.view(-1)\n            masks_flat = masks.view(-1)\n\n            loss = criterion(outputs_flat, masks_flat)\n            total_test_loss += loss.item()\n\n            outputs_thresholded = outputs_thresholded.cpu().detach().numpy().reshape(-1)\n            masks = masks.cpu().detach().numpy().reshape(-1)\n\n            accuracy = accuracy_function(masks, outputs_thresholded)\n            precision = precision_function(masks, outputs_thresholded)\n            recall = recall_function(masks, outputs_thresholded)\n            dice_score = dice_coeff_binary(masks, outputs_thresholded)\n            specificity = specificity_function(masks, outputs_thresholded)\n            iou = intersection_over_union(masks, outputs_thresholded)\n\n            total_test_accuracy += accuracy\n            total_test_precision += precision\n            total_test_recall += recall\n            total_test_dice += dice_score\n            total_test_specificity += specificity\n            total_iou += iou\n\n        avg_test_accuracy = total_test_accuracy / len(test_loader)\n        avg_test_precision = total_test_precision / len(test_loader)\n        avg_test_recall = total_test_recall / len(test_loader)\n        avg_test_dice = total_test_dice / len(test_loader)\n        avg_test_specificity = total_test_specificity / len(test_loader)\n        avg_test_loss = total_test_loss / len(test_loader)\n        avg_test_iou = total_iou / len(test_loader)\n        \n        print(f\"Test Loss: {avg_test_loss}, Average Accuracy: {avg_test_accuracy}, Average Precision: {avg_test_precision}, Average Recall: {avg_test_recall}, Average Dice: {avg_test_dice}, Average Specificity: {avg_test_specificity}, Average IOU: {avg_test_iou}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample Segmentations","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel.eval()\n\nwith torch.no_grad():\n    for i, (images, masks) in enumerate(test_loader):\n        images = images.cuda()\n        masks = masks.cuda()\n\n        outputs = model(images)\n        threshold = 0.5\n        outputs_thresholded = (outputs > threshold).float()\n\n        for j in range(min(images.shape[0], 50)):\n            plt.figure(figsize=(15, 5))\n\n            # Plot the input image\n            plt.subplot(1, 3, 1)\n            plt.imshow(images[j].cpu().permute(1, 2, 0))\n            plt.title(\"Image\")\n            plt.axis(\"off\")\n\n            plt.subplot(1, 3, 2)\n            plt.imshow(masks[j].cpu().squeeze(), cmap='gray')\n            plt.title(\"Ground truth\")\n            plt.axis(\"off\")\n\n            plt.subplot(1, 3, 3)\n            plt.imshow(outputs_thresholded[j].cpu().squeeze(), cmap='gray')\n            plt.title(\"Predicted mask\")\n            plt.axis(\"off\")\n\n            plt.show()\n\n        if i * test_loader.batch_size + images.shape[0] >= 50:\n            break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}